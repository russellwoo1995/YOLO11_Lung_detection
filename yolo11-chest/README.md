# ä½¿ç”¨yolo11è¿›è¡Œçš„è‚ºç»“èŠ‚æ£€æµ‹ï¼ˆLuna2016ï¼‰

ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³

è§†é¢‘åœ°å€ï¼š[æ‰‹æŠŠæ‰‹æ•™ä½ ä½¿ç”¨YOLO11å®ç°è½¦è¾†æ£€æµ‹ä¸è¿½è¸ªç³»ç»Ÿ_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1nzzdYwE2g/)

ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³

å„ä½å°ä¼™ä¼´ï¼Œå¤§å®¶å¥½ï¼Œè¿™é‡Œæ˜¯è‚†åäºŒï¼Œä»Šå¤©æˆ‘ç»™å¤§å®¶å¸¦äº†çš„æ˜¯åŸºäºyolo11çš„è‚ºç»“èŠ‚æ£€æµ‹ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿä½¿ç”¨tt100käº¤é€šè¯†åˆ«æ•°æ®è¿›è¡Œå¼€å‘ï¼Œä¸€å…±åŒ…å«æœ‰42ä¸ªç±»çš„è‚ºç»“èŠ‚ï¼Œæˆ‘ä»¬åˆ†åˆ«åŸºäºyolov5ã€yolov8å’Œyolo11è¿›è¡Œäº†è®­ç»ƒã€‚æœ¬åšå®¢ä¸­æˆ‘ä»¬å°†ä¼šæŒ‰ç…§æ•™ä¼šå¤§å®¶å¯¹è¿™ä¸ªæ•°æ®é›†è¿›è¡Œè®­ç»ƒã€æµ‹è¯•ä»¥åŠä½¿ç”¨å›¾å½¢åŒ–çš„ç•Œé¢è¿›è¡Œæ¨¡å‹çš„åŠ è½½æ¥å®Œæˆå›¾åƒå’Œè§†é¢‘çš„æ£€æµ‹ï¼Œæ•ˆæœå›¾å¦‚ä¸‹æ‰€ç¤ºã€‚

![image-20241211204235380](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241211204235380.png)

![image-20241211204736357](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241211204736357.png)

![image-20241211204753525](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241211204753525.png)

## é¡¹ç›®å®æˆ˜

è¿›è¡Œé¡¹ç›®å®æˆ˜ä¹‹å‰è¯·åŠ¡å¿…å®‰è£…å¥½pytorchå’Œminicondaã€‚

ä¸ä¼šçš„å°ä¼™ä¼´è¯·çœ‹è¿™é‡Œï¼š[Pythoné¡¹ç›®é…ç½®å‰çš„å‡†å¤‡å·¥ä½œ-CSDNåšå®¢](https://blog.csdn.net/ECHOSON/article/details/144233262?sharetype=blogdetail&sharerId=144233262&sharerefer=PC&sharesource=ECHOSON&spm=1011.2480.3001.8118)

### ç¯å¢ƒé…ç½®

æ‰§è¡Œä¸‹åˆ—æŒ‡ä»¤åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

```bash
conda create -n yolo python==3.8.5
conda activate yolo
```

æ‰§è¡Œä¸‹åˆ—æ‰§è¡Œå®‰è£…pytorch

```bash
conda install pytorch==1.8.0 torchvision torchaudio cudatoolkit=10.2 # æ³¨æ„è¿™æ¡å‘½ä»¤æŒ‡å®šPytorchçš„ç‰ˆæœ¬å’Œcudaçš„ç‰ˆæœ¬
conda install pytorch==1.10.0 torchvision torchaudio cudatoolkit=11.3 # 30ç³»åˆ—ä»¥ä¸Šæ˜¾å¡gpuç‰ˆæœ¬pytorchå®‰è£…æŒ‡ä»¤
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cpuonly # CPUçš„å°ä¼™ä¼´ç›´æ¥æ‰§è¡Œè¿™æ¡å‘½ä»¤å³å¯
conda install pytorch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0 cudatoolkit=11.3 #æœåŠ¡å™¨çš„å°ä¼™ä¼´ä½¿ç”¨è¿™ä¸ª
```

åœ¨**é¡¹ç›®ç›®å½•ä¸‹**æ‰§è¡Œä¸‹åˆ—æŒ‡ä»¤è¿›è¡Œå…¶ä»–åº“çš„å®‰è£…

```bash
pip install -v -e .
```

ç¯å¢ƒåˆ›å»ºå®Œæˆä¹‹åè¯·ä½¿ç”¨pycharmæ‰“å¼€ä½ çš„é¡¹ç›®ï¼Œå¹¶åœ¨pycharmçš„å³ä¸‹è§’é€‰æ‹©ä½ é¡¹ç›®å¯¹åº”çš„è™šæ‹Ÿç¯å¢ƒã€‚

### æœ¬åœ°æ¨¡å‹è®­ç»ƒ

æ¨¡å‹è®­ç»ƒä½¿ç”¨çš„è„šæœ¬ä¸º` step1_start_train.py `ï¼Œè¿›è¡Œæ¨¡å‹è®­ç»ƒä¹‹å‰ï¼Œè¯·å…ˆæŒ‰ç…§é…ç½®å¥½ä½ æœ¬åœ°çš„æ•°æ®é›†ã€‚æ•°æ®é›†åœ¨` ultralytics\cfg\datasets\A_my_data.yaml`ç›®å½•ä¸‹ï¼Œä½ éœ€è¦å°†æ•°æ®é›†çš„æ ¹ç›®å½•æ›´æ¢ä¸ºä½ è‡ªå·±æœ¬åœ°çš„ç›®å½•ã€‚

![image-20241204100852481](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204100852481.png)

æ›´æ¢ä¹‹åä¿®æ”¹è®­ç»ƒè„šæœ¬é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œç›´æ¥å³é”®å³å¯å¼€å§‹è®­ç»ƒã€‚

![image-20241204100955839](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204100955839.png)

å¦‚æœä½ æƒ³è¦åœ¨gpuä¸Šè®­ç»ƒï¼Œè¯·å°†è¿™é‡Œçš„deviceè®¾ç½®ä¸º0

![image-20241204101046196](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204101046196.png)

è®­ç»ƒå¼€å§‹å‰å¦‚æœå‡ºç°æŠ¥é”™ï¼Œæœ‰å¾ˆå¤§çš„å¯èƒ½æ˜¯æ•°æ®é›†çš„è·¯å¾„æ²¡æœ‰é…ç½®æ­£ç¡®ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†çš„è·¯å¾„ï¼Œä¿è¯æ•°æ®é›†é…ç½®æ²¡æœ‰é—®é¢˜ã€‚è®­ç»ƒä¹‹åçš„ç»“æœå°†ä¼šä¿å­˜åœ¨runsç›®å½•ä¸‹ã€‚

![image-20241204101214326](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204101214326.png)

### GPUæœåŠ¡å™¨è®­ç»ƒï¼ˆå¯é€‰ï¼‰

ç›®å‰è“è€˜GPUå¯ä»¥è–…ç¾Šæ¯›ï¼Œæ¨èå°ä¼™ä¼´ä»è¿™ä¸ªç½‘ç«™ä½¿ç”¨GPUäº‘æ¥è¿›è¡Œè®­ç»ƒï¼Œæ–°ç”¨æˆ·æ³¨å†Œä¼šè·å¾—30å…ƒçš„ä»£é‡‘åˆ¸ã€‚

æ³¨å†Œåœ°å€ï¼š[è“è€˜GPUæ™ºç®—äº‘å¹³å°](https://cloud.lanyun.net/#/registerPage?promoterCode=5c9cd7436a)

æœåŠ¡å™¨ä½¿ç”¨æŒ‡å—ï¼š[æ‰‹æŠŠæ‰‹æ•™ä½ ä½¿ç”¨æœåŠ¡å™¨è®­ç»ƒAIæ¨¡å‹_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1TuxLeVED6?vd_source=2f9a4e63109c3db3be5e8078e5111776&spm_id_from=333.788.videopod.sections)

### æ¨¡å‹æµ‹è¯•

æ¨¡å‹çš„æµ‹è¯•ä¸»è¦æ˜¯å¯¹mapã€pã€rç­‰æŒ‡æ ‡è¿›è¡Œè®¡ç®—ï¼Œä½¿ç”¨çš„è„šæœ¬ä¸º` step2_start_val.py`ï¼Œæ¨¡å‹åœ¨è®­ç»ƒçš„æœ€åä¸€è½®å·²ç»æ‰§è¡Œäº†æµ‹è¯•ï¼Œå…¶å®è¿™ä¸ªæ­¥éª¤å®Œå…¨å¯ä»¥è·³è¿‡ï¼Œä½†æ˜¯æœ‰çš„æœ‹å‹å¯èƒ½æƒ³è¦å•ç‹¬éªŒè¯ï¼Œé‚£ä½ åªéœ€è¦æ›´æ”¹æµ‹è¯•è„šæœ¬ä¸­çš„æƒé‡ä¸ºä½ è‡ªå·±æ‰€è®­ç»ƒçš„æƒé‡è·¯å¾„ï¼Œå³å¯å•ç‹¬è¿›è¡Œæµ‹è¯•ã€‚

![image-20241204101429118](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204101429118.png)

### å›¾å½¢åŒ–ç•Œé¢å°è£…

å›¾å½¢åŒ–ç•Œé¢è¿›è¡Œäº†å‡çº§ï¼Œæœ¬æ¬¡å›¾å½¢åŒ–ç•Œé¢çš„å¼€å‘æˆ‘ä»¬ä½¿ç”¨pyside6æ¥è¿›è¡Œå¼€å‘ã€‚**PySide6** æ˜¯ä¸€ä¸ªå¼€æºçš„Pythonåº“ï¼Œå®ƒæ˜¯Qt 6æ¡†æ¶çš„Pythonç»‘å®šã€‚Qt æ˜¯ä¸€ä¸ªè·¨å¹³å°çš„åº”ç”¨ç¨‹åºå¼€å‘æ¡†æ¶ï¼Œä¸»è¦ç”¨äºå¼€å‘å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰åº”ç”¨ç¨‹åºï¼ŒåŒæ—¶ä¹Ÿæä¾›äº†ä¸°å¯Œçš„åŠŸèƒ½æ¥å¤„ç†éå›¾å½¢åº”ç”¨ç¨‹åºçš„ä»»åŠ¡ï¼ˆå¦‚æ•°æ®åº“ã€ç½‘ç»œç¼–ç¨‹ç­‰ï¼‰ã€‚PySide6 ä½¿å¾—å¼€å‘è€…èƒ½å¤Ÿä½¿ç”¨ Python ç¼–å†™ Qt 6 åº”ç”¨ç¨‹åºï¼Œå› æ­¤ï¼Œå®ƒæä¾›äº†Pythonçš„çµæ´»æ€§å’ŒQt 6çš„å¼ºå¤§åŠŸèƒ½ã€‚å›¾å½¢åŒ–ç•Œé¢æä¾›äº†å›¾ç‰‡å’Œè§†é¢‘æ£€æµ‹ç­‰å¤šä¸ªåŠŸèƒ½ï¼Œå›¾å½¢åŒ–ç•Œé¢çš„ç¨‹åºä¸º` step3_start_window_track.py `ã€‚

å¦‚æœä½ é‡æ–°è®­ç»ƒäº†æ¨¡å‹ï¼Œéœ€è¦æ›¿æ¢ä¸ºä½ è‡ªå·±çš„æ¨¡å‹ï¼Œè¯·åœ¨è¿™é‡Œè¿›è¡Œæ“ä½œã€‚

![image-20241204101842858](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204101842858.png)

å¦‚æœä½ æƒ³è¦å¯¹å›¾å½¢åŒ–ç•Œé¢çš„é¢˜ç›®ã€logoç­‰è¿›è¡Œä¿®æ”¹ï¼Œç›´æ¥åœ¨è¿™é‡Œä¿®æ”¹å…¨å±€å˜é‡å³å¯ã€‚

![image-20241204101949741](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204101949741.png)

ç™»å½•ä¹‹åä¸Šä¼ å›¾åƒæˆ–è€…æ˜¯ä¸Šä¼ è§†é¢‘è¿›è¡Œæ£€æµ‹å³å¯ã€‚



![image-20241211204235380](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241211204235380.png)

![image-20241211204736357](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241211204736357.png)

![image-20241211204753525](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241211204753525.png)

## æ–‡æ¡£

### èƒŒæ™¯ä¸æ„ä¹‰

ä½¿ç”¨YOLOv11è¿›è¡Œè‚ºç»“èŠ‚æ£€æµ‹çš„èƒŒæ™¯å’Œæ„ä¹‰ä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

1. **æé«˜è‚ºç™Œæ—©æœŸç­›æŸ¥çš„æ•ˆç‡å’Œå‡†ç¡®æ€§**ï¼šè‚ºç™Œæ˜¯å…¨çƒå‘ç—…ç‡å’Œæ­»äº¡ç‡æœ€é«˜çš„æ¶æ€§è‚¿ç˜¤ä¹‹ä¸€ï¼Œæ—©æœŸå‘ç°è‚ºç»“èŠ‚å¯¹äºè‚ºç™Œçš„é¢„é˜²å’Œæ²»ç–—è‡³å…³é‡è¦ã€‚YOLOv11ä½œä¸ºä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œèƒ½å¤Ÿæé«˜è‚ºç»“èŠ‚çš„æ£€æµ‹ç‡ï¼Œå°¤å…¶æ˜¯åœ¨æ—©æœŸè‚ºç™Œç­›æŸ¥ä¸­ã€‚

2. **å‡è½»åŒ»ç”Ÿå·¥ä½œè´Ÿæ‹…**ï¼šéšç€CTæ•°æ®çš„å¢åŠ ï¼Œä½¿ç”¨è®¡ç®—æœºè¾…åŠ©è¯Šæ–­ï¼ˆCADï¼‰ç³»ç»Ÿå¯ä»¥å¤§å¤§å‡å°‘æ”¾å°„ç§‘åŒ»ç”Ÿçš„å·¥ä½œé‡ï¼Œå¹¶é™ä½æ¼è¯Šç‡ã€‚

3. **æé«˜æ£€æµ‹çš„æ³›åŒ–èƒ½åŠ›å’Œå‡†ç¡®æ€§**ï¼šYOLOv11æ¨¡å‹é€šè¿‡ç»“åˆå›¾åƒå¢å¼ºã€å™ªå£°è¿‡æ»¤å’Œæ•°æ®æ‰©å……ç­‰é¢„å¤„ç†æ­¥éª¤ï¼Œèƒ½å¤Ÿå­¦ä¹ åˆ°è‚ºç»“èŠ‚çš„å¤šç§ç‰¹å¾ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œå‡†ç¡®æ€§ã€‚

4. **å‡å°‘è¯¯è¯Šå’Œæ¼è¯Š**ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒYOLOv11åœ¨è‚ºç»“èŠ‚æ£€æµ‹ä»»åŠ¡ä¸­å…·æœ‰è¾ƒé«˜çš„ç²¾åº¦å’Œå¬å›ç‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘å‡é˜³æ€§å’Œå‡é˜´æ€§çš„å‘ç”Ÿã€‚

5. **æé«˜æ£€æµ‹é€Ÿåº¦**ï¼šä¸ä¼ ç»Ÿçš„æ£€æµ‹æ–¹æ³•ç›¸æ¯”ï¼ŒYOLOv11åœ¨æ£€æµ‹é€Ÿåº¦å’Œç²¾åº¦ä¸Šéƒ½å…·æœ‰æ˜æ˜¾çš„ä¼˜åŠ¿ï¼Œä¸ºåŒ»å­¦å½±åƒæ™ºèƒ½åˆ†ææä¾›äº†åˆ‡å®å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚

6. **è¾…åŠ©ä¸´åºŠè¯Šæ–­**ï¼šYOLOv11ä¸ä»…èƒ½å¤Ÿå‡è½»åŒ»ç”Ÿçš„å·¥ä½œè´Ÿæ‹…ï¼Œè¿˜å¯ä»¥é€šè¿‡å…¶é«˜æ•ˆæ€§å’Œå¯é æ€§ä¸ºåŒ»ç–—è¯Šæ–­æä¾›æœ‰åŠ›çš„æŠ€æœ¯æ”¯æŒã€‚

7. **æ¨åŠ¨ä¸ªæ€§åŒ–åŒ»ç–—çš„å‘å±•**ï¼šé€šè¿‡è‚ºç»“èŠ‚çš„æ—©æœŸæ£€æµ‹å’Œè¯Šæ–­ï¼ŒYOLOv11æœ‰åŠ©äºä¿ƒè¿›ä¸ªæ€§åŒ–åŒ»ç–—çš„å‘å±•ï¼Œæœ€ç»ˆæé«˜æ‚£è€…çš„ç”Ÿå­˜ç‡å’Œç”Ÿæ´»è´¨é‡ã€‚

8. **æ¢ç´¢æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å½±åƒåˆ†æä¸­çš„åº”ç”¨**ï¼šYOLOv11çš„ç ”ç©¶ä¸ä»…å“åº”äº†åŒ»å­¦å½±åƒåˆ†æé¢†åŸŸå¯¹é«˜æ•ˆã€å‡†ç¡®çš„è‡ªåŠ¨åŒ–å·¥å…·çš„è¿«åˆ‡éœ€æ±‚ï¼Œä¹Ÿä¸ºæ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨åŒ»å­¦é¢†åŸŸçš„åº”ç”¨æ¢ç´¢æä¾›äº†æ–°çš„æ–¹å‘ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œä½¿ç”¨YOLOv11è¿›è¡Œè‚ºç»“èŠ‚æ£€æµ‹å…·æœ‰é‡è¦çš„ä¸´åºŠæ„ä¹‰å’Œç ”ç©¶ä»·å€¼ï¼Œå®ƒä¸ä»…èƒ½å¤Ÿæé«˜è‚ºç»“èŠ‚æ£€æµ‹çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œè¿˜èƒ½å¤Ÿè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œæ›´å‡†ç¡®çš„è¯Šæ–­ï¼Œä»è€Œåœ¨è‚ºç™Œçš„æ—©æœŸå‘ç°å’Œæ²»ç–—ä¸­å‘æŒ¥å…³é”®ä½œç”¨ã€‚

### ç›¸å…³æ–‡çŒ®ç»¼è¿°

éšç€CTæ•°æ®çš„æ—¥ç›Šå¢é•¿ï¼Œä½¿ç”¨è®¡ç®—æœºè¾…åŠ©è¯Šæ–­(CAD)ç³»ç»Ÿå¯ä»¥æå¤§å‡å°‘æ”¾å°„ç§‘åŒ»ç”Ÿçš„å·¥ä½œé‡ä»¥åŠé™ä½æ¼æ£€ç‡ã€‚CADç³»ç»Ÿé€šè¿‡è‚ºå®è´¨åˆ†å‰²ã€å€™é€‰ç»“èŠ‚æ£€æµ‹ä»¥åŠå‡é˜³æ€§å‰”é™¤ä¸‰ä¸ªé˜¶æ®µæ¥å®ç°è‚ºç»“èŠ‚çš„é«˜æ•ˆæ£€æµ‹ã€‚

è‚ºå®è´¨åˆ†å‰²æ˜¯æ£€æµ‹å‰çš„é‡è¦é¢„å¤„ç†æ­¥éª¤ï¼Œå…¶ç›®çš„æ˜¯å°†è‚ºç»“èŠ‚çš„æ£€æµ‹èŒƒå›´é™åˆ¶åœ¨è‚ºéƒ¨åŒºåŸŸã€‚ç ”ç©¶ä¸­æå‡ºäº†ç»“åˆU-Netä¸ä¼ ç»Ÿå›¾åƒå¤„ç†æ–¹æ³•çš„è‚ºå®è´¨åˆ†å‰²æŠ€æœ¯ï¼Œä»¥åŠç»“åˆResNetå’ŒRCNNçš„åˆ†å‰²æ¨¡å‹RU-Netå’ŒR2U-Netï¼Œè¿™äº›æ¨¡å‹åœ¨è‚ºå®è´¨åˆ†å‰²æ•°æ®é›†ä¸Šå–å¾—äº†è¾ƒé«˜çš„Diceç³»æ•°

æ—©æœŸçš„å€™é€‰ç»“èŠ‚æ£€æµ‹å¤šé‡‡ç”¨é˜ˆå€¼åˆ†å‰²ã€å½¢æ€å­¦è¿ç®—ç­‰ä¼ ç»Ÿæ–¹æ³•ï¼Œä½†è¿™äº›æ–¹æ³•éš¾ä»¥æå–åˆ°åˆ¤åˆ«æ€§ç‰¹å¾ï¼Œå¯¼è‡´å‡é˜³æ€§å€™é€‰ç»“èŠ‚çš„ç”Ÿæˆã€‚éšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„å€™é€‰ç»“èŠ‚æ£€æµ‹æ–¹æ³•ï¼Œå¦‚ç»“åˆ3D RPNçš„æ–¹æ³•ï¼Œä»¥åŠåŸºäº3D Faster RCNNçš„å¤šä»»åŠ¡ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†æ£€æµ‹çš„çµæ•åº¦å’Œå‡†ç¡®æ€§

å°½ç®¡ç°æœ‰çš„è‚ºç»“èŠ‚æ£€æµ‹æ–¹æ³•å–å¾—äº†è¾ƒä¸ºæ»¡æ„çš„æ•ˆæœï¼Œä½†ä»å­˜åœ¨æŒ‘æˆ˜ï¼Œå¦‚åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ä¾èµ–äºå¤§é‡é«˜è´¨é‡çš„é‡‘æ ‡å‡†æ•°æ®ï¼Œè€Œç°æœ‰çš„èƒ¸éƒ¨CTå…¬å¼€æ•°æ®é›†å¹¶æ²¡æœ‰è¿›è¡Œæœ‰åºçš„æ ‡è®°ï¼Œå¯¼è‡´é‡‘æ ‡å‡†æ•°æ®ç¨€ç¼ºã€‚æœªæ¥çš„ç ”ç©¶éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ç®—æ³•ï¼Œæé«˜æ£€æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶è§£å†³æ•°æ®æ ‡æ³¨å’Œéšç§ä¿æŠ¤çš„é—®é¢˜ã€‚

### æœ¬æ–‡ç®—æ³•ä»‹ç»

yoloç³»åˆ—å·²ç»åœ¨ä¸šç•Œå¯è°“æ˜¯å®¶å–»æˆ·æ™“äº†ï¼Œä¸‹é¢æ˜¯yolo11æ”¾å‡ºçš„æ€§èƒ½æµ‹è¯•å›¾ï¼Œå…¶ä¸­è¿™ç§å›¾çš„æ¨ªè½´ä¸ºæ¨¡å‹çš„é€Ÿåº¦ï¼Œä¸€èˆ¬æƒ…å†µä¸‹æ¨¡å‹çš„é€Ÿåº¦æ˜¯é€šè¿‡è°ƒæ•´å·ç§¯çš„æ·±åº¦å’Œå®½åº¦æ¥è¿›è¡Œä¿®æ”¹çš„ï¼Œçºµè½´åˆ™è¡¨ç¤ºæ¨¡å‹çš„ç²¾åº¦ï¼Œå¯ä»¥çœ‹åˆ°åœ¨åŒæ ·çš„é€Ÿåº¦ä¸‹ï¼Œ11è¡¨ç°å‡ºæ›´é«˜çš„ç²¾åº¦ã€‚

![image-20241024170914031](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241024170914031.png)

YOLOæ¶æ„çš„æ ¸å¿ƒç”±ä¸‰ä¸ªåŸºæœ¬ç»„ä»¶ç»„æˆã€‚é¦–å…ˆï¼Œä¸»å¹²ä½œä¸ºä¸»è¦ç‰¹å¾æå–å™¨ï¼Œåˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œå°†åŸå§‹å›¾åƒæ•°æ®è½¬æ¢æˆå¤šå°ºåº¦ç‰¹å¾å›¾ã€‚å…¶æ¬¡ï¼Œé¢ˆéƒ¨ç»„ä»¶ä½œä¸ºä¸­é—´å¤„ç†é˜¶æ®µï¼Œä½¿ç”¨ä¸“é—¨çš„å±‚æ¥èšåˆå’Œå¢å¼ºä¸åŒå°ºåº¦çš„ç‰¹å¾è¡¨ç¤ºã€‚ç¬¬ä¸‰ï¼Œå¤´éƒ¨åˆ†é‡ä½œä¸ºé¢„æµ‹æœºåˆ¶ï¼Œæ ¹æ®ç²¾ç»†åŒ–çš„ç‰¹å¾æ˜ å°„ç”Ÿæˆç›®æ ‡å®šä½å’Œåˆ†ç±»çš„æœ€ç»ˆè¾“å‡ºã€‚åŸºäºè¿™ä¸ªå·²å»ºç«‹çš„ä½“ç³»ç»“æ„ï¼ŒYOLO11æ‰©å±•å¹¶å¢å¼ºäº†YOLOv8å¥ å®šçš„åŸºç¡€ï¼Œå¼•å…¥äº†ä½“ç³»ç»“æ„åˆ›æ–°å’Œå‚æ•°ä¼˜åŒ–ï¼Œä»¥å®ç°å¦‚å›¾1æ‰€ç¤ºçš„å“è¶Šæ£€æµ‹æ€§èƒ½ã€‚ä¸‹é¢æ˜¯yolo11æ¨¡å‹æ‰€èƒ½æ”¯æŒçš„ä»»åŠ¡ï¼Œç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€ç‰©ä½“åˆ†ç±»ã€å§¿æ€ä¼°è®¡ã€æ—‹è½¬ç›®æ ‡æ£€æµ‹å’Œç›®æ ‡è¿½è¸ªä»–éƒ½å¯ä»¥ï¼Œå¦‚æœä½ æƒ³è¦é€‰æ‹©ä¸€ä¸ªæ·±åº¦å­¦ä¹ ç®—æ³•æ¥è¿›è¡Œå…¥é—¨ï¼Œé‚£ä¹ˆyolo11å°†ä¼šæ˜¯ä½ ç»ä½³çš„é€‰æ‹©ã€‚

![image-20241024171109729](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241024171109729.png)

ä¸ºäº†èƒ½å¤Ÿè®©å¤§å®¶å¯¹yolo11ç½‘ç»œæœ‰æ¯”è¾ƒæ¸…æ™°çš„ç†è§£ï¼Œä¸‹é¢æˆ‘å°†ä¼šå¯¹yolo11çš„ç»“æ„è¿›è¡Œæ‹†è§£ã€‚

é¦–å…ˆæ˜¯yolo11çš„ç½‘ç»œç»“æ„æ•´ä½“é¢„è§ˆï¼Œå…¶ä¸­backboneçš„éƒ¨åˆ†ä¸»è¦è´Ÿè´£åŸºç¡€çš„ç‰¹å¾æå–ã€neckçš„éƒ¨åˆ†è´Ÿè´£ç‰¹å¾çš„èåˆï¼Œheadçš„éƒ¨åˆ†è´Ÿè´£è§£ç ï¼Œè®©ä½ çš„ç½‘ç»œå¯ä»¥é€‚é…ä¸åŒçš„è®¡ç®—æœºè§†è§‰çš„ä»»åŠ¡ã€‚

![image-20241024173654996](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241024173654996.png)

* ä¸»å¹²ç½‘ç»œï¼ˆBackBoneï¼‰

  * Conv

    å·ç§¯æ¨¡å—æ˜¯ä¸€ä¸ªå¸¸è§„çš„å·ç§¯æ¨¡å—ï¼Œåœ¨yoloä¸­ä½¿ç”¨çš„éå¸¸å¤šï¼Œå¯ä»¥è®¾è®¡å·ç§¯çš„å¤§å°å’Œæ­¥é•¿ï¼Œä»£ç çš„è¯¦ç»†å®ç°å¦‚ä¸‹ï¼š

    ```python
    class Conv(nn.Module):
        """Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)."""
    
        default_act = nn.SiLU()  # default activation
    
        def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
            """Initialize Conv layer with given arguments including activation."""
            super().__init__()
            self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)
            self.bn = nn.BatchNorm2d(c2)
            self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()
    
        def forward(self, x):
            """Apply convolution, batch normalization and activation to input tensor."""
            return self.act(self.bn(self.conv(x)))
    
        def forward_fuse(self, x):
            """Perform transposed convolution of 2D data."""
            return self.act(self.conv(x))
    ```

  * C3k2

    C3k2å—è¢«æ”¾ç½®åœ¨å¤´éƒ¨çš„å‡ ä¸ªé€šé“ä¸­ï¼Œç”¨äºå¤„ç†ä¸åŒæ·±åº¦çš„å¤šå°ºåº¦ç‰¹å¾ã€‚ä»–çš„ä¼˜åŠ¿æœ‰ä¸¤ä¸ªæ–¹é¢ã€‚ä¸€ä¸ªæ–¹é¢æ˜¯è¿™ä¸ªæ¨¡å—æä¾›äº†æ›´å¿«çš„å¤„ç†:ä¸å•ä¸ªå¤§å·ç§¯ç›¸æ¯”ï¼Œä½¿ç”¨ä¸¤ä¸ªè¾ƒå°çš„å·ç§¯å¯ä»¥å‡å°‘è®¡ç®—å¼€é”€ï¼Œä»è€Œæ›´å¿«åœ°æå–ç‰¹å¾ã€‚å¦ä¸€ä¸ªæ–¹é¢æ˜¯è¿™ä¸ªæ¨¡å—æä¾›äº†æ›´å¥½çš„å‚æ•°æ•ˆç‡: C3k2æ˜¯CSPç“¶é¢ˆçš„ä¸€ä¸ªæ›´ç´§å‡‘çš„ç‰ˆæœ¬ï¼Œä½¿æ¶æ„åœ¨å¯è®­ç»ƒå‚æ•°çš„æ•°é‡æ–¹é¢æ›´é«˜æ•ˆã€‚

    C3k2æ¨¡å—ä¸»è¦æ˜¯ä¸ºäº†å¢åŠ ç‰¹å¾çš„å¤šæ ·æ€§ï¼Œå…¶ä¸­è¿™å—æ¨¡å—æ˜¯ç”±C3kæ¨¡å—æ¼”å˜è€Œæ¥ã€‚å®ƒé€šè¿‡å…è®¸è‡ªå®šä¹‰å†…æ ¸å¤§å°æä¾›äº†å¢å¼ºçš„çµæ´»æ€§ã€‚C3kçš„é€‚åº”æ€§å¯¹äºä»å›¾åƒä¸­æå–æ›´è¯¦ç»†çš„ç‰¹å¾ç‰¹åˆ«æœ‰ç”¨ï¼Œæœ‰åŠ©äºæé«˜æ£€æµ‹ç²¾åº¦ã€‚C3kçš„å®ç°å¦‚ä¸‹ã€‚

    ```python
    class C3k(C3):
        """C3k is a CSP bottleneck module with customizable kernel sizes for feature extraction in neural networks."""
    
        def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, k=3):
            """Initializes the C3k module with specified channels, number of layers, and configurations."""
            super().__init__(c1, c2, n, shortcut, g, e)
            c_ = int(c2 * e)  # hidden channels
            # self.m = nn.Sequential(*(RepBottleneck(c_, c_, shortcut, g, k=(k, k), e=1.0) for _ in range(n)))
            self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=(k, k), e=1.0) for _ in range(n)))
    ```

    å¦‚æœå°†c3kä¸­çš„nè®¾ç½®ä¸º2ï¼Œåˆ™æ­¤æ—¶çš„æ¨¡å—å³ä¸ºC3K2æ¨¡å—ï¼Œç½‘ç»œç»“æ„å›¾å¦‚ä¸‹æ‰€ç¤ºã€‚

    ![image-20241025121912923](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241025121912923.png)

    è¯¥ç½‘ç»œçš„å®ç°ä»£ç å¦‚ä¸‹ã€‚

    ```python
    class C3k2(C2f):
        """Faster Implementation of CSP Bottleneck with 2 convolutions."""
    
        def __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):
            """Initializes the C3k2 module, a faster CSP Bottleneck with 2 convolutions and optional C3k blocks."""
            super().__init__(c1, c2, n, shortcut, g, e)
            self.m = nn.ModuleList(
                C3k(self.c, self.c, 2, shortcut, g) if c3k else Bottleneck(self.c, self.c, shortcut, g) for _ in range(n)
            )
    ```

  * C2PSA

    PSAçš„æ¨¡å—èµ·åˆåœ¨YOLOv10ä¸­æå‡ºï¼Œé€šè¿‡è‡ªæ³¨æ„åŠ›çš„æœºåˆ¶å¢åŠ ç‰¹å¾çš„è¡¨è¾¾èƒ½åŠ›ï¼Œç›¸å¯¹äºä¼ ç»Ÿçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶è€Œè¨€ï¼Œè®¡ç®—é‡åˆç›¸å¯¹è¾ƒå°ã€‚ç½‘ç»œçš„ç»“æ„å›¾å¦‚ä¸‹æ‰€ç¤ºï¼Œå…¶ä¸­å›¾ä¸­çš„mhsaè¡¨ç¤ºçš„æ˜¯å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ŒFFNè¡¨ç¤ºå‰é¦ˆç¥ç»ç½‘ç»œã€‚

    ![image-20241025122617233](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241025122617233.png)

    

  åœ¨è¿™ä¸ªåŸºç¡€ä¸Šæ·»åŠ ç»™åŸå…ˆçš„C2æ¨¡å—ä¸Šæ·»åŠ ä¸€ä¸ªPSAçš„æ—è·¯åˆ™æ„æˆäº†C2PSAçš„æ¨¡å—ï¼Œè¯¥æ¨¡å—çš„ç¤ºæ„å›¾å¦‚ä¸‹ã€‚

  ![image-20241025122752167](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241025122752167.png)

  ç½‘ç»œå®ç°å¦‚ä¸‹ï¼š

  ```python
  class C2PSA(nn.Module):
      """
      C2PSA module with attention mechanism for enhanced feature extraction and processing.
  
      This module implements a convolutional block with attention mechanisms to enhance feature extraction and processing
      capabilities. It includes a series of PSABlock modules for self-attention and feed-forward operations.
  
      Attributes:
          c (int): Number of hidden channels.
          cv1 (Conv): 1x1 convolution layer to reduce the number of input channels to 2*c.
          cv2 (Conv): 1x1 convolution layer to reduce the number of output channels to c.
          m (nn.Sequential): Sequential container of PSABlock modules for attention and feed-forward operations.
  
      Methods:
          forward: Performs a forward pass through the C2PSA module, applying attention and feed-forward operations.
  
      Notes:
          This module essentially is the same as PSA module, but refactored to allow stacking more PSABlock modules.
  
      Examples:
          >>> c2psa = C2PSA(c1=256, c2=256, n=3, e=0.5)
          >>> input_tensor = torch.randn(1, 256, 64, 64)
          >>> output_tensor = c2psa(input_tensor)
      """
  
      def __init__(self, c1, c2, n=1, e=0.5):
          """Initializes the C2PSA module with specified input/output channels, number of layers, and expansion ratio."""
          super().__init__()
          assert c1 == c2
          self.c = int(c1 * e)
          self.cv1 = Conv(c1, 2 * self.c, 1, 1)
          self.cv2 = Conv(2 * self.c, c1, 1)
  
          self.m = nn.Sequential(*(PSABlock(self.c, attn_ratio=0.5, num_heads=self.c // 64) for _ in range(n)))
  
      def forward(self, x):
          """Processes the input tensor 'x' through a series of PSA blocks and returns the transformed tensor."""
          a, b = self.cv1(x).split((self.c, self.c), dim=1)
          b = self.m(b)
          return self.cv2(torch.cat((a, b), 1))
  
  ```

* é¢ˆéƒ¨ç½‘ç»œï¼ˆNeckï¼‰

  * upsample

    è¿™é‡Œæ˜¯ä¸€ä¸ªå¸¸ç”¨çš„ä¸Šé‡‡æ ·çš„æ–¹å¼ï¼Œåœ¨YOLO11çš„æ¨¡å‹ä¸­ï¼Œè¿™é‡Œä¸€èˆ¬ä½¿ç”¨æœ€è¿‘é‚»å·®å€¼çš„æ–¹å¼æ¥è¿›è¡Œå®ç°ã€‚åœ¨ `torch`ï¼ˆPyTorchï¼‰ä¸­ï¼Œ`upsample` æ“ä½œæ˜¯ç”¨äºå¯¹å¼ é‡ï¼ˆé€šå¸¸æ˜¯å›¾åƒæˆ–ç‰¹å¾å›¾ï¼‰è¿›è¡Œ**ä¸Šé‡‡æ ·**ï¼ˆå¢å¤§å°ºå¯¸ï¼‰çš„æ“ä½œã€‚ä¸Šé‡‡æ ·çš„ä¸»è¦ç›®çš„æ˜¯å¢åŠ ç‰¹å¾å›¾çš„ç©ºé—´åˆ†è¾¨ç‡ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­é€šå¸¸ç”¨äº**å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰**ä¸­ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„ç‰¹å¾å›¾ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»»åŠ¡å¦‚ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ä¸­ã€‚

    PyTorch ä¸­çš„ `torch.nn.functional.upsample` åœ¨è¾ƒæ—©ç‰ˆæœ¬æä¾›äº†ä¸Šé‡‡æ ·åŠŸèƒ½ï¼Œä½†åœ¨æ–°çš„ç‰ˆæœ¬ä¸­æ¨èä½¿ç”¨ `torch.nn.functional.interpolate`ï¼ŒåŠŸèƒ½ç›¸åŒï¼Œä½†æ›´åŠ çµæ´»å’Œæ ‡å‡†åŒ–ã€‚

    ä¸»è¦å‚æ•°å¦‚ä¸‹ï¼š

    `torch.nn.functional.interpolate` å‡½æ•°ç”¨äºä¸Šé‡‡æ ·ï¼Œæ”¯æŒä¸åŒçš„æ’å€¼æ–¹æ³•ï¼Œå¸¸ç”¨çš„å‚æ•°å¦‚ä¸‹ï¼š

    ```python
    torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None)
    ```

    - `input`ï¼šè¾“å…¥çš„å¼ é‡ï¼Œé€šå¸¸æ˜¯ 4D çš„å¼ é‡ï¼Œå½¢çŠ¶ä¸º `(batch_size, channels, height, width)`ã€‚

    - `size`ï¼šè¾“å‡ºçš„ç›®æ ‡å°ºå¯¸ï¼Œå¯ä»¥æ˜¯æ•´å‹çš„é«˜åº¦å’Œå®½åº¦ï¼ˆå¦‚ `(height, width)`ï¼‰ï¼Œè¡¨ç¤ºå¸Œæœ›å°†ç‰¹å¾å›¾è°ƒæ•´åˆ°çš„å…·ä½“å°ºå¯¸ã€‚

    - `scale_factor`ï¼šä¸Šé‡‡æ ·çš„ç¼©æ”¾å› å­ã€‚ä¾‹å¦‚ï¼Œ`scale_factor=2` è¡¨ç¤ºç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦éƒ½æ‰©å¤§ 2 å€ã€‚å¦‚æœè®¾ç½®äº† `scale_factor`ï¼Œåˆ™ä¸éœ€è¦å†è®¾ç½® `size`ã€‚

    - ```
      mode
      ```

      ï¼šæ’å€¼çš„æ–¹å¼ï¼Œæœ‰å¤šç§å¯é€‰æ’å€¼ç®—æ³•ï¼š

      - `'nearest'`ï¼šæœ€è¿‘é‚»æ’å€¼ï¼ˆé»˜è®¤ï¼‰ã€‚ç›´æ¥å¤åˆ¶æœ€è¿‘çš„åƒç´ å€¼ï¼Œè®¡ç®—ç®€å•ï¼Œé€Ÿåº¦å¿«ï¼Œä½†ç”Ÿæˆå›¾åƒå¯èƒ½æ¯”è¾ƒç²—ç³™ã€‚
      - `'linear'`ï¼šåŒçº¿æ€§æ’å€¼ï¼Œé€‚ç”¨äº 3D è¾“å…¥ï¼ˆå³ 1D ç‰¹å¾å›¾ï¼‰ã€‚
      - `'bilinear'`ï¼šåŒçº¿æ€§æ’å€¼ï¼Œé€‚ç”¨äº 4D è¾“å…¥ï¼ˆå³ 2D ç‰¹å¾å›¾ï¼‰ã€‚
      - `'trilinear'`ï¼šä¸‰çº¿æ€§æ’å€¼ï¼Œé€‚ç”¨äº 5D è¾“å…¥ï¼ˆå³ 3D ç‰¹å¾å›¾ï¼‰ã€‚
      - `'bicubic'`ï¼šåŒä¸‰æ¬¡æ’å€¼ï¼Œè®¡ç®—æ›´å¤æ‚ï¼Œä½†ç”Ÿæˆçš„å›¾åƒæ›´å¹³æ»‘ã€‚

    - `align_corners`ï¼šåœ¨ä½¿ç”¨åŒçº¿æ€§ã€ä¸‰çº¿æ€§ç­‰æ’å€¼æ—¶å†³å®šæ˜¯å¦å¯¹é½è§’ç‚¹ã€‚å¦‚æœä¸º `True`ï¼Œè¾“å…¥å’Œè¾“å‡ºç‰¹å¾å›¾çš„è§’ç‚¹ä¼šå¯¹é½ï¼Œé€šå¸¸ä¼šä½¿æ’å€¼ç»“æœæ›´åŠ ç²¾ç¡®ã€‚

  * Concat

    åœ¨YOLOï¼ˆYou Only Look Onceï¼‰ç›®æ ‡æ£€æµ‹ç½‘ç»œä¸­ï¼Œ`concat`ï¼ˆè¿æ¥ï¼‰æ“ä½œæ˜¯ç”¨äºå°†æ¥è‡ªä¸åŒå±‚çš„ç‰¹å¾å›¾æ‹¼æ¥èµ·æ¥çš„æ“ä½œã€‚å…¶ä½œç”¨æ˜¯èåˆä¸åŒå°ºåº¦çš„ç‰¹å¾ä¿¡æ¯ï¼Œä»¥ä¾¿ç½‘ç»œèƒ½å¤Ÿåœ¨å¤šä¸ªå°ºåº¦ä¸Šæ›´å¥½åœ°è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚è°ƒæ•´å¥½å°ºå¯¸åï¼Œæ²¿ç€**é€šé“ç»´åº¦**å°†ç‰¹å¾å›¾è¿›è¡Œæ‹¼æ¥ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸¤ä¸ªç‰¹å¾å›¾ï¼Œåˆ†åˆ«å…·æœ‰å½¢çŠ¶ (H, W, C1) å’Œ (H, W, C2)ï¼Œæ‹¼æ¥åå¾—åˆ°çš„ç‰¹å¾å›¾å½¢çŠ¶å°†æ˜¯ (H, W, C1+C2)ï¼Œå³é€šé“æ•°å¢åŠ äº†ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œåœ¨è¿›è¡Œconcatæ“ä½œä¹‹åä¼šå†è¿›è¡Œä¸€æ¬¡å·ç§¯çš„æ“ä½œï¼Œé€šè¿‡å·ç§¯çš„æ“ä½œå¯ä»¥å°†é€šé“æ•°è°ƒæ•´åˆ°ç†æƒ³çš„å¤§å°ã€‚è¯¥æ“ä½œçš„å®ç°å¦‚ä¸‹ã€‚

    ```python
    class Concat(nn.Module):
        """Concatenate a list of tensors along dimension."""
    
        def __init__(self, dimension=1):
            """Concatenates a list of tensors along a specified dimension."""
            super().__init__()
            self.d = dimension
    
        def forward(self, x):
            """Forward pass for the YOLOv8 mask Proto module."""
            return torch.cat(x, self.d)
    ```

* å¤´éƒ¨ï¼ˆHeadï¼‰

  YOLOv11çš„Headè´Ÿè´£ç”Ÿæˆç›®æ ‡æ£€æµ‹å’Œåˆ†ç±»æ–¹é¢çš„æœ€ç»ˆé¢„æµ‹ã€‚å®ƒå¤„ç†ä»é¢ˆéƒ¨ä¼ é€’çš„ç‰¹å¾æ˜ å°„ï¼Œæœ€ç»ˆè¾“å‡ºå›¾åƒå†…å¯¹è±¡çš„è¾¹ç•Œæ¡†å’Œç±»æ ‡ç­¾ã€‚ä¸€èˆ¬è´Ÿè´£å°†ç‰¹å¾è¿›è¡Œæ˜ å°„åˆ°ä½ å¯¹åº”çš„ä»»åŠ¡ä¸Šï¼Œå¦‚æœæ˜¯æ£€æµ‹ä»»åŠ¡ï¼Œå¯¹åº”çš„å°±æ˜¯4ä¸ªè¾¹ç•Œæ¡†çš„å€¼ä»¥åŠ1ä¸ªç½®ä¿¡åº¦çš„å€¼å’Œä¸€ä¸ªç‰©ä½“ç±»åˆ«çš„å€¼ã€‚å¦‚ä¸‹æ‰€ç¤ºã€‚

  ```python
  # Ultralytics YOLO ğŸš€, AGPL-3.0 license
  """Model head modules."""
  
  import copy
  import math
  
  import torch
  import torch.nn as nn
  from torch.nn.init import constant_, xavier_uniform_
  
  from ultralytics.utils.tal import TORCH_1_10, dist2bbox, dist2rbox, make_anchors
  
  from .block import DFL, BNContrastiveHead, ContrastiveHead, Proto
  from .conv import Conv, DWConv
  from .transformer import MLP, DeformableTransformerDecoder, DeformableTransformerDecoderLayer
  from .utils import bias_init_with_prob, linear_init
  
  __all__ = "Detect", "Segment", "Pose", "Classify", "OBB", "RTDETRDecoder", "v10Detect"
  
  
  ```

åŸºäºä¸Šé¢çš„è®¾è®¡ï¼Œyolo11è¡ç”Ÿå‡ºäº†å¤šç§å˜ç§ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚ä»–ä»¬å¯ä»¥æ”¯æŒä¸åŒçš„ä»»åŠ¡å’Œä¸åŒçš„æ¨¡å‹å¤§å°ï¼Œåœ¨æœ¬æ¬¡çš„æ•™å­¦ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å›´ç»•æ£€æµ‹è¿›è¡Œè®²è§£ï¼Œåç»­çš„è¿‡ç¨‹ä¸­ï¼Œè¿˜ä¼šå¯¹åˆ†å‰²ã€å§¿æ€ä¼°è®¡ç­‰ä»»åŠ¡è¿›è¡Œè®²è§£ã€‚

![image-20241024173356022](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241024173356022.png)

YOLOv11ä»£è¡¨äº†CVé¢†åŸŸçš„é‡å¤§è¿›æ­¥ï¼Œæä¾›äº†å¢å¼ºæ€§èƒ½å’Œå¤šåŠŸèƒ½æ€§çš„å¼•äººæ³¨ç›®çš„ç»„åˆã€‚YOLOæ¶æ„çš„æœ€æ–°è¿­ä»£åœ¨ç²¾åº¦å’Œå¤„ç†é€Ÿåº¦æ–¹é¢æœ‰äº†æ˜¾è‘—çš„æ”¹è¿›ï¼ŒåŒæ—¶å‡å°‘äº†æ‰€éœ€å‚æ•°çš„æ•°é‡ã€‚è¿™æ ·çš„ä¼˜åŒ–ä½¿å¾—YOLOv11ç‰¹åˆ«é€‚åˆå¹¿æ³›çš„åº”ç”¨ç¨‹åºï¼Œä»è¾¹ç¼˜è®¡ç®—åˆ°åŸºäºäº‘çš„åˆ†æã€‚è¯¥æ¨¡å‹å¯¹å„ç§ä»»åŠ¡çš„é€‚åº”æ€§ï¼ŒåŒ…æ‹¬å¯¹è±¡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²å’Œå§¿æ€ä¼°è®¡ï¼Œä½¿å…¶æˆä¸ºå„ç§è¡Œä¸š(å¦‚æƒ…æ„Ÿæ£€æµ‹ã€åŒ»ç–—ä¿å¥å’Œå„ç§å…¶ä»–è¡Œä¸š)çš„æœ‰ä»·å€¼çš„å·¥å…·ã€‚å®ƒçš„æ— ç¼é›†æˆèƒ½åŠ›å’Œæé«˜çš„æ•ˆç‡ä½¿å…¶æˆä¸ºå¯»æ±‚å®æ–½æˆ–å‡çº§å…¶CVç³»ç»Ÿçš„ä¼ä¸šçš„ä¸€ä¸ªæœ‰å¸å¼•åŠ›çš„é€‰æ‹©ã€‚æ€»ä¹‹ï¼ŒYOLOv11å¢å¼ºçš„ç‰¹å¾æå–ã€ä¼˜åŒ–çš„æ€§èƒ½å’Œå¹¿æ³›çš„ä»»åŠ¡æ”¯æŒä½¿å…¶æˆä¸ºè§£å†³ç ”ç©¶å’Œå®é™…åº”ç”¨ä¸­å¤æ‚è§†è§‰è¯†åˆ«æŒ‘æˆ˜çš„å¼ºå¤§è§£å†³æ–¹æ¡ˆã€‚

### å®éªŒç»“æœåˆ†æ

#### æ•°æ®é›†ä»‹ç»

æœ¬æ¬¡æˆ‘ä»¬ä½¿ç”¨çš„æ•°æ®é›†ä¸ºLUNA 2016 ï¼š[æ•°æ®é›†å®˜æ–¹åœ°å€]([Home - LUNA16 - Grand Challenge](https://luna16.grand-challenge.org/))
LUNA 2016 æ•°æ®é›†æ¥è‡ª2016å¹´LUng Nodule Analysisæ¯”èµ›ï¼Œè¿™é‡Œæ˜¯å…¶å®˜æ–¹ç½‘ç«™ã€‚
LUNA16æ•°æ®é›†æ˜¯æœ€å¤§å…¬ç”¨è‚ºç»“èŠ‚æ•°æ®é›†LIDC-IDRIçš„å­é›†ï¼ŒLIDC-IDRIå®ƒåŒ…æ‹¬1018ä¸ªä½å‰‚é‡çš„è‚ºéƒ¨CTå½±åƒã€‚LIDC-IDRIåˆ é™¤äº†åˆ‡ç‰‡åšåº¦å¤§äº3mmå’Œè‚ºç»“èŠ‚å°äº3mmçš„CTå½±åƒï¼Œå‰©ä¸‹çš„å°±æ˜¯LUNA16æ•°æ®é›†äº†ã€‚
å…¶æ•°æ®é›†çš„æ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š

1. subset0.zip~subset9.zip åŒ…å«æ‰€æœ‰CTå›¾åƒçš„10ä¸ªzipæ–‡ä»¶ï¼Œæ•°æ®æ ¼å¼ä¸ºâ€œ.mhdâ€,â€œ.rawâ€
2. CSVFILESæ–‡ä»¶å¤¹ï¼ŒåŒ…æ‹¬3æ–‡ä»¶ï¼šannotations.csvï¼Œcandidates.csvï¼ŒsampleSubmission.csv
3. annotations.csvï¼š1186ä¸ªè‚ºç»“èŠ‚ä¿¡æ¯ï¼Œå­—æ®µæœ‰seriesuid,coordX,coordY,coordZ,diameter_mm
4. candidates.csvï¼šä¸€å…±551065æ¡æ•°æ®ã€‚å…¶ä¸­ï¼Œæ­£ä¾‹ï¼ˆclassï¼š1ï¼‰ï¼š1351æ¡ï¼Œå…¶ä½™éƒ½æ˜¯è´Ÿä¾‹ï¼ˆclassï¼š0ï¼‰
5. sampleSubmission.csvï¼šæ­£ç¡®æ ¼å¼çš„æäº¤æ–‡ä»¶ç¤ºä¾‹ï¼Œæˆ‘ä»¬ä¸æäº¤ï¼Œæš‚æ—¶æ²¡ç”¨ã€‚

**mdhæ•°æ®æ ¼å¼è¯¦è§£**
è¿™é‡Œæœ‰ä¸€ç¯‡å¾ˆå¥½çš„æ–‡ç« ï¼Œå…³äºåŒ»ç–—å½±åƒçš„mhdå’Œdcmæ ¼å¼å›¾åƒçš„è¯»å–å’Œåæ ‡è½¬æ¢
æ¯ä¸ªç—…ä¾‹çš„æ•°æ®çš„å­˜å‚¨éƒ½æ˜¯ç”±ä¸€ä¸ª.mhdå’Œä¸€ä¸ª.rawæ ¼å¼çš„æ–‡ä»¶ç»„æˆã€‚.mdhæ˜¯è¯´æ˜æ–‡ä»¶ï¼Œå…·ä½“æ•°æ®åœ¨.rawæ–‡ä»¶ä¸­ï¼Œmdhçš„æ ·ä¾‹å¦‚ä¸‹ï¼š

```
ObjectType = Image
NDims = 3          #ä¸‰ç»´æ•°æ®
BinaryData = True              #äºŒè¿›åˆ¶æ•°æ®
BinaryDataByteOrderMSB = False
CompressedData = False
TransformMatrix = 1 0 0 0 1 0 0 0 1        #100,010,001 åˆ†åˆ«ä»£è¡¨x,y,z
Offset = -195 -195 -378       #åŸç‚¹åæ ‡
CenterOfRotation = 0 0 0
AnatomicalOrientation = RAI
ElementSpacing = 0.7617189884185791 0.7617189884185791 2.5     #åƒç´ é—´éš” x,y,z
DimSize = 512 512 141        #æ•°æ®çš„å¤§å° x,y,z
ElementType = MET_SHORT
ElementDataFile = 1.3.6.1.4.1.14519.5.2.1.6279.6001.173106154739244262091404659845.raw      #æ•°æ®å­˜å‚¨çš„æ–‡ä»¶å

```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨pythonä¸­çš„simpleITKåº“å¯¹mdhæ–‡ä»¶è¿›è¡Œè§£æï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
import SimpleITK as sitk
import matplotlib.pyplot as plt
case_path = './1.3.6.1.4.1.14519.5.2.1.6279.6001.126264578931778258890371755354.mhd'  
itkimage = sitk.ReadImage(case_path)   #è¿™éƒ¨åˆ†ç»™å‡ºäº†å…³äºå›¾åƒçš„ä¿¡æ¯,å¯ä»¥æ‰“å°å¤„ç†æŸ¥çœ‹ï¼Œè¿™é‡Œå°±ä¸åœ¨æ˜¾ç¤ºäº†
#print(itkimage)
image = sitk.GetArrayFromImage(itkimage)     #z,y,x
#æŸ¥çœ‹ç¬¬100å¼ å›¾åƒ
plt.figure()
plt.imshow(image[100,:,:]) 

```

å¦å¤–ï¼Œä¸ºäº†è·å¾—è‚ºç»“èŠ‚çš„ä½ç½®ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦å¯¹annotations.csvæ–‡ä»¶è¿›è¡Œä½œä¸ºåæ ‡è½¬åŒ–ã€‚

annotations.csvä¸­æä¾›äº†åŒ»ç”Ÿæ ‡æ³¨è‚ºç»“èŠ‚ä½ç½®ä¿¡æ¯
seriesuidï¼šè¡¨ç¤ºæ¯ä¸ªç—…ä¾‹å›¾åƒå¯¹åº”çš„æ–‡ä»¶å
coordXï¼ŒcoordXï¼ŒcoordXï¼Œdiameter_mm:è¡¨ç¤ºåŒ»ç”Ÿæ ‡æ³¨çš„ç»“èŠ‚ä½ç½®ä¿¡æ¯å’Œç›´å¾„

![img](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/e0b47bf813a1b6b586730fa25cd047f6.png)

åœ¨ä½¿coordXç”¨å·ç§¯ç½‘ç»œå¯¹è‚ºç»“èŠ‚è¿›è¡Œæ£€æµ‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®åŒ»ç”Ÿæä¾›çš„æ ‡æ³¨ä¿¡æ¯ï¼Œåœ¨å›¾åƒä¸­æ‰¾åˆ°ç›¸åº”çš„è‚ºç»“èŠ‚ä½ç½®ï¼Œæ¥ä¸‹æ¥è¯´åŒ»ç”Ÿæ ‡æ³¨çš„åæ ‡ä¸å›¾åƒä¸­çš„åæ ‡çš„å…³ç³»ã€‚
mhdä¸­ç»™å®šäº†å›¾åƒä¸­çš„åŸç‚¹åæ ‡ä¸ºï¼ˆ-195 ï¼Œ-195 ï¼Œ-378ï¼‰ #x,y,z
åƒç´ é—´éš”ä¸ºï¼ˆ0.7617189884185791ï¼Œ0.7617189884185791ï¼Œ2.5ï¼‰ #x,y,z
é€šè¿‡ä»¥ä¸Šä¿¡æ¯å¯ä»¥è®¡ç®—ç»“èŠ‚ç›¸å¯¹åŸç‚¹çš„åæ ‡ï¼Œç„¶åç”¨è¿™ä¸ªåæ ‡é™¤ä»¥åƒç´ é—´éš”ï¼Œå³ä¸ºåœ¨å›¾åƒä¸­å¯¹åº”çš„ç»“èŠ‚ä½ç½®
#ä¸–ç•Œåæ ‡è½¬æ¢åˆ°å›¾åƒä¸­çš„åæ ‡ï¼Œå‡½æ•°å¦‚ä¸‹ï¼š

```python
def worldToVoxelCoord(worldCoord, origin, spacing):
    stretchedVoxelCoord = np.absolute(worldCoord - origin)
    voxelCoord = stretchedVoxelCoord / spacing
    return voxelCoord
```

å›¾åƒä¸Šçš„åæ ‡è½¬åŒ–ä¸ºä¸–ç•Œåæ ‡çš„è„šæœ¬å¦‚ä¸‹

```python
def VoxelToWorldCoord(voxelCoord, origin, spacing):
    strechedVocelCoord = voxelCoord * spacing
    worldCoord = strechedVocelCoord + origin
    return worldCoord
```

è®©æˆ‘ä»¬ä¸€èµ·å¯è§†åŒ–çœ‹ä¸‹æ•ˆæœã€‚

```python
import SimpleITK as sitk
import matplotlib.pyplot as plt
import numpy as np
filename='data\\1.3.6.1.4.1.14519.5.2.1.6279.6001.173106154739244262091404659845.mhd'
itkimage = sitk.ReadImage(filename)#è¯»å–.mhdæ–‡ä»¶
OR=itkimage.GetOrigin()
print(OR)
SP=itkimage.GetSpacing()
print(SP)
numpyImage = sitk.GetArrayFromImage(itkimage)#è·å–æ•°æ®ï¼Œè‡ªåŠ¨ä»åŒåçš„.rawæ–‡ä»¶è¯»å–

def show_nodules(ct_scan, nodules,Origin,Spacing,radius=20, pad=2, max_show_num=4): # radiusæ˜¯æ­£æ–¹å½¢è¾¹é•¿ä¸€åŠï¼Œpadæ˜¯è¾¹çš„å®½åº¦,max_show_numæœ€å¤§å±•ç¤ºæ•°
    show_index = []
    for idx in range(nodules.shape[0]): # lableæ˜¯ä¸€ä¸ªnx4ç»´çš„æ•°ç»„ï¼Œnæ˜¯è‚ºç»“èŠ‚æ•°ç›®ï¼Œ4ä»£è¡¨x,y,z,ä»¥åŠç›´å¾„
        if idx < max_show_num:
            if abs(nodules[idx, 0]) + abs(nodules[idx, 1]) + abs(nodules[idx, 2]) + abs(nodules[idx, 3]) == 0:
                continue

            x, y, z = int((nodules[idx, 0]-Origin[0])/SP[0]), int((nodules[idx, 1]-Origin[1])/SP[1]), int((nodules[idx, 2]-Origin[2])/SP[2])
        print(x, y, z)
        data = ct_scan[z]
        radius=int(nodules[idx, 3]/SP[0]/2)
        #pad = 2*radius
        # æ³¨æ„ yä»£è¡¨çºµè½´ï¼Œxä»£è¡¨æ¨ªè½´
        data[max(0, y - radius):min(data.shape[0], y + radius),
        max(0, x - radius - pad):max(0, x - radius)] = 3000 # ç«–çº¿
        data[max(0, y - radius):min(data.shape[0], y + radius),
        min(data.shape[1], x + radius):min(data.shape[1], x + radius + pad)] = 3000 # ç«–çº¿
        data[max(0, y - radius - pad):max(0, y - radius),
        max(0, x - radius):min(data.shape[1], x + radius)] = 3000 # æ¨ªçº¿
        data[min(data.shape[0], y + radius):min(data.shape[0], y + radius + pad),
        max(0, x - radius):min(data.shape[1], x + radius)] = 3000 # æ¨ªçº¿

        if z in show_index: # æ£€æŸ¥æ˜¯å¦æœ‰ç»“èŠ‚åœ¨åŒä¸€å¼ åˆ‡ç‰‡ï¼Œå¦‚æœæœ‰ï¼Œåªæ˜¾ç¤ºä¸€å¼ 
            continue
        show_index.append(z)
        plt.figure(idx)
        plt.imshow(data, cmap='gray')

    plt.show()

b = np.array([[-116.2874457,21.16102581,-124.619925,10.88839157],[-111.1930507,-1.264504521,-138.6984478,17.39699158],[73.77454834,37.27831567,-118.3077904,8.648347161]])
show_nodules(numpyImage,b,OR,SP)
```

å¯è§†åŒ–ä¹‹åçš„ç»“æœå¦‚ä¸‹æ‰€ç¤º

![image-20241212100559083](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241212100559083.png)

æˆ‘åœ¨è¿™é‡Œå·²ç»å°†è‚ºç»“èŠ‚çš„æ•°æ®æŒ‰ç…§yoloæ ¼å¼è¿›è¡Œäº†å¤„ç†ï¼Œå¤§å®¶åªéœ€è¦åœ¨é…ç½®æ–‡ä»¶ç§å¯¹æœ¬åœ°çš„æ•°æ®åœ°å€è¿›è¡Œé…ç½®å³å¯ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

```yaml
path: /root/autodl-tmp/yolo-data/tt100/reTT100K
train: # train images (relative to 'path')  16551 images
  - images/train
val: # val images (relative to 'path')  4952 images
  - images/val
test: # test images (optional)
  - images/test

names: ['i2','i4','i5','il100','i160','il80','io','ip','p10','p11',
 'p12','p19','p23','p26','p27','p3','p5','pÃ³','pg','ph4','ph4.5',
 'pl100','pl120','pl20','pl30','pl40','pl5','pl50','pl60','pl70',
 'pL80','pm20','pm30','pm55','pn','pne','po','pr40','w13','w55',
 'w57', 'w59']
```

ä¸‹é¢æ˜¯æ•°æ®é›†çš„éƒ¨åˆ†ç¤ºä¾‹ã€‚

![val_batch0_labels](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/val_batch0_labels.jpg)

ä»¥åŠä¸‹é¢æ˜¯æ•°æ®é›†ä¸­æ¯ä¸ªç±»åˆ«å¯¹åº”çš„å®ä¾‹æ•°é‡å’Œè¾¹ç•Œæ¡†å¤§å°çš„åŸºæœ¬åˆ†æï¼Œä»ä¸‹å›¾å¯ä»¥çœ‹å‡ºï¼Œå¤§éƒ¨åˆ†ç›®æ ‡éƒ½æ¯”è¾ƒå°ï¼Œå±äºæ˜¯å°ç›®æ ‡æ£€æµ‹çš„å†…å®¹ã€‚

![labels - chest](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/labels%20-%20chest.jpg)

#### å®éªŒç»“æœåˆ†æ

å®éªŒç»“æœçš„æŒ‡æ ‡å›¾å‡ä¿å­˜åœ¨runsç›®å½•ä¸‹ï¼Œ å¤§å®¶åªéœ€è¦å¯¹å®éªŒè¿‡ç¨‹å’ŒæŒ‡æ ‡å›¾çš„ç»“æœè¿›è¡Œè§£æå³å¯ã€‚

å¦‚æœåªæŒ‡æ ‡å›¾çš„å®šä¹‰ä¸æ¸…æ™°ï¼Œè¯·çœ‹è¿™ä¸ªä½ç½®ï¼š[YOLO11æ¨¡å‹æŒ‡æ ‡è§£è¯»-mAPã€Precisionã€Recall_yolo11æ¨¡å‹è®­ç»ƒç‰¹å¾å›¾-CSDNåšå®¢](https://blog.csdn.net/ECHOSON/article/details/144097341)

![results-chest](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/results-chest.png)

train/box_lossï¼ˆè®­ç»ƒé›†çš„è¾¹ç•Œæ¡†æŸå¤±ï¼‰ï¼šéšç€è®­ç»ƒè½®æ¬¡çš„å¢åŠ ï¼Œè¾¹ç•Œæ¡†æŸå¤±é€æ¸é™ä½ï¼Œè¡¨æ˜æ¨¡å‹åœ¨å­¦ä¹ æ›´å‡†ç¡®åœ°å®šä½ç›®æ ‡ã€‚
train/cls_lossï¼ˆè®­ç»ƒé›†çš„åˆ†ç±»æŸå¤±ï¼‰ï¼šåˆ†ç±»æŸå¤±åœ¨åˆæœŸè¿…é€Ÿä¸‹é™ï¼Œç„¶åè¶‹äºå¹³ç¨³ï¼Œè¯´æ˜æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸æé«˜äº†å¯¹è‚ºç»“èŠ‚çš„åˆ†ç±»å‡†ç¡®æ€§ã€‚
train/dfl_lossï¼ˆè®­ç»ƒé›†çš„åˆ†å¸ƒå¼ç„¦ç‚¹æŸå¤±ï¼‰ï¼šè¯¥æŸå¤±åŒæ ·å‘ˆç°ä¸‹é™è¶‹åŠ¿ï¼Œè¡¨æ˜æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼˜åŒ–äº†é¢„æµ‹æ¡†ä¸çœŸå®æ¡†ä¹‹é—´çš„åŒ¹é…ã€‚
metrics/precision(B)ï¼ˆç²¾ç¡®åº¦ï¼‰ï¼šç²¾ç¡®åº¦éšç€è®­ç»ƒè½®æ¬¡çš„å¢åŠ è€Œæé«˜ï¼Œè¯´æ˜æ¨¡å‹åœ¨å‡å°‘è¯¯æŠ¥æ–¹é¢è¡¨ç°è¶Šæ¥è¶Šå¥½ã€‚
metrics/recall(B)ï¼ˆå¬å›ç‡ï¼‰ï¼šå¬å›ç‡ä¹Ÿåœ¨é€æ¸ä¸Šå‡ï¼Œè¡¨æ˜æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«å‡ºæ›´å¤šçš„çœŸå®è‚ºç»“èŠ‚ã€‚
val/box_lossï¼ˆéªŒè¯é›†çš„è¾¹ç•Œæ¡†æŸå¤±ï¼‰ï¼šéªŒè¯é›†çš„è¾¹ç•Œæ¡†æŸå¤±åŒæ ·ä¸‹é™ï¼Œä½†å¯èƒ½å­˜åœ¨ä¸€äº›æ³¢åŠ¨ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºéªŒè¯é›†çš„å¤šæ ·æ€§æˆ–è¿‡æ‹Ÿåˆçš„è¿¹è±¡ã€‚
val/cls_lossï¼ˆéªŒè¯é›†çš„åˆ†ç±»æŸå¤±ï¼‰ï¼šéªŒè¯é›†çš„åˆ†ç±»æŸå¤±ä¸‹é™è¶‹åŠ¿ä¸è®­ç»ƒé›†ç›¸ä¼¼ï¼Œä½†å¯èƒ½åœ¨æŸäº›ç‚¹ä¸Šå‡ºç°æ³¢åŠ¨ã€‚
val/dfl_lossï¼ˆéªŒè¯é›†çš„åˆ†å¸ƒå¼ç„¦ç‚¹æŸå¤±ï¼‰ï¼šéªŒè¯é›†çš„åˆ†å¸ƒå¼ç„¦ç‚¹æŸå¤±ä¹Ÿåœ¨ä¸‹é™ï¼Œä½†å¯èƒ½å­˜åœ¨ä¸€äº›æ³¢åŠ¨ï¼Œè¿™éœ€è¦è¿›ä¸€æ­¥è§‚å¯Ÿä»¥ç¡®å®šæ˜¯å¦æ˜¯è¿‡æ‹Ÿåˆçš„è¿¹è±¡ã€‚
metrics/mAP50(B)ï¼ˆåœ¨IoUé˜ˆå€¼ä¸º0.5æ—¶çš„å¹³å‡ç²¾åº¦ï¼‰ï¼šmAP50éšç€è®­ç»ƒè½®æ¬¡çš„å¢åŠ è€Œæé«˜ï¼Œè¡¨æ˜æ¨¡å‹åœ¨æ£€æµ‹ä»»åŠ¡ä¸Šçš„æ•´ä½“æ€§èƒ½åœ¨æå‡ã€‚
metrics/mAP50-95(B)ï¼ˆåœ¨IoUé˜ˆå€¼ä»0.5åˆ°0.95çš„å¹³å‡ç²¾åº¦ï¼‰ï¼šmAP50-95çš„æé«˜è¡¨æ˜æ¨¡å‹åœ¨ä¸åŒIoUé˜ˆå€¼ä¸‹çš„æ€§èƒ½éƒ½åœ¨æå‡ï¼Œè¿™æ˜¯ä¸€ä¸ªæ›´ä¸¥æ ¼çš„æ€§èƒ½æŒ‡æ ‡ã€‚

<img src="https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/PR_curve-chest.png" alt="PR_curve-chest" style="zoom:29%;" />

å½“ioué˜ˆå€¼ä¸º0.5çš„æ—¶å€™ï¼Œæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„mapå¯ä»¥è¾¾åˆ°68.1%ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªé¢„æµ‹å›¾åƒï¼Œå¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥æœ‰æ•ˆçš„é¢„æµ‹å‡ºè¿™äº›å°ºåº¦æ¯”è¾ƒå°çš„äº¤é€šç›®æ ‡ã€‚

![val_batch1_pred-chest](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/val_batch1_pred-chest.jpg)

### ç»“è®º

ç»¼ä¸Šæ‰€è¿°ï¼ŒåŸºäºYOLOv11çš„è‚ºç»“èŠ‚æ£€æµ‹ç³»ç»Ÿä¸ºåŒ»å­¦å½±åƒåˆ†æé¢†åŸŸæä¾›äº†ä¸€ç§é«˜æ•ˆã€å‡†ç¡®çš„è§£å†³æ–¹æ¡ˆï¼Œæœ‰æœ›åœ¨ä¸´åºŠå®è·µä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œä»è€Œæé«˜è‚ºç™Œçš„æ—©æœŸè¯Šæ–­ç‡å’Œæ²»ç–—æˆåŠŸç‡ã€‚

### å‚è€ƒæ–‡çŒ®

[1] ç‹å¾·æ­,æ±ªå®¶æ—º,äºç«‹ç‡•,ç­‰.è‚ºç»“èŠ‚æ£€æµ‹ç®—æ³•ç ”ç©¶[J].ç”Ÿç‰©åŒ»å­¦å·¥ç¨‹å­¦è¿›å±•, 2005, 26(001):3-7.DOI:10.3969/j.issn.1674-1242.2005.01.001.

[2] é«˜å›­å›­,å•åº†æ–‡,éƒ­å®,ç­‰.ä¸€ç§æ–°çš„è‚ºç»“èŠ‚æ£€æµ‹ç®—æ³•[J].è®¡ç®—æœºå·¥ç¨‹ä¸åº”ç”¨, 2007, 43(23):2.DOI:10.3321/j.issn:1002-8331.2007.23.060.

[3] æä¸½.åŸºäºCTå½±åƒåˆ†æçš„è‚ºç»“èŠ‚æ£€æµ‹ç®—æ³•ç ”ç©¶[D].å¤§è¿ç†å·¥å¤§å­¦,2010.DOI:CNKI:CDMD:2.1011.023110.

[4]   Zhou Q , Yu C . Point RCNN: An Angle-Free Framework for Rotated Object Detection[J]. Remote Sensing, 2022, 14.

[5]  Zhang, Y., Li, H., Bu, R., Song, C., Li, T., Kang, Y., & Chen, T. (2020). Fuzzy Multi-objective Requirements for NRP Based on Particle Swarm Optimization. *International Conference on Adaptive and Intelligent Systems*.

[6]   Li X , Deng J , Fang Y . Few-Shot Object Detection on Remote Sensing Images[J]. IEEE Transactions on Geoscience and Remote Sensing, 2021(99).

[7]   Su W, Zhu X, Tao C, et al. Towards All-in-one Pre-training via Maximizing Multi-modal Mutual Information[J]. arXiv preprint arXiv:2211.09807, 2022.

[8]   Chen Q, Wang J, Han C, et al. Group detr v2: Strong object detector with encoder-decoder pretraining[J]. arXiv preprint arXiv:2211.03594, 2022.

[9]   Liu, Shilong, et al. "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection." arXiv preprint arXiv:2303.05499 (2023).

[10] Redmon J, Divvala S, Girshick R, et al. You only look once: Unified, real-time object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 779-788.

[11] Redmon J, Farhadi A. YOLO9000: better, faster, stronger[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 7263-7271.

[12] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint arXiv:1804.02767, 2018.

[13] Tian Z, Shen C, Chen H, et al. Fcos: Fully convolutional one-stage object detection[C]//Proceedings of the IEEE/CVF international conference on computer vision. 2019: 9627-9636.

[14] Chen L C, Zhu Y, Papandreou G, et al. Encoder-decoder with atrous separable convolution for semantic image segmentation[C]//Proceedings of the European conference on computer vision (ECCV). 2018: 801-818.

[15] Liu W, Anguelov D, Erhan D, et al. Ssd: Single shot multibox detector[C]//Computer Visionâ€“ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11â€“14, 2016, Proceedings, Part I 14. Springer International Publishing, 2016: 21-37.

[16] Lin T Y, DollÃ¡r P, Girshick R, et al. Feature pyramid networks for object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 2117-2125.

[17] Cai Z, Vasconcelos N. Cascade r-cnn: Delving into high quality object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 6154-6162.

[18] Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[J]. Advances in neural information processing systems, 2015, 28.

[19] Wang R, Shivanna R, Cheng D, et al. Dcn v2: Improved deep & cross network and practical lessons for web-scale learning to rank systems[C]//Proceedings of the web conference 2021. 2021: 1785-1797.

[20] Chen L C, Papandreou G, Schroff F, et al. Rethinking atrous convolution for semantic image segmentation[J]. arXiv preprint arXiv:1706.05587, 2017.
